<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=theme content="hugo-academic-group">
<script src=https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js></script>
<script src=https://uvpicl.live//js/hugo-academic-group.js></script>
<link rel=stylesheet href=https://uvpicl.live//css/bootstrap.min.css>
<script src=https://uvpicl.live//js/bootstrap.min.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/default.min.css>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/github-fork-ribbon-css/0.2.2/gh-fork-ribbon.min.css>
<script src=https://uvpicl.live//js/highlight.pack.js></script>
<script>hljs.initHighlightingOnLoad()</script>
<link rel=stylesheet href=https://uvpicl.live//css/font-awesome.min.css>
<link rel=stylesheet href=https://uvpicl.live//css/academicons.min.css>
<link rel=stylesheet href=https://uvpicl.live//css/biaslab-font.css>
<link rel=stylesheet href="//fonts.googleapis.com/css?family=Lato:100,300,400,700|Merriweather:100,400,700|Roboto+Mono">
<link rel=stylesheet href=https://uvpicl.live//css/hugo-academic-group.css>
<link rel="shortcut icon" href=https://uvpicl.live//img/favicon.ico type=image/x-icon>
<link rel=canonical href=https://uvpicl.live/publication/identity-aware-facial-expression-recognition-via-deep-metric-learning-based-on-synthesized-images/>
<title>Identity-aware Facial Expression Recognition via Deep Metric Learning based on Synthesized Images | Universal Visual Perception & Intelligent Computing Laboratory</title>
</head>
<body>
<div class=home-anchor id=home></div>
<nav class="navbar navbar-default navbar-fixed-top" id=navbar-main>
<div class=container>
<div class=navbar-header>
<button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=.navbar-collapse aria-expanded=false>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<div class=navbar-brand>
</div>
</div>
<div class="collapse navbar-collapse" id=#navbar-collapse-1>
<ul class="nav navbar-nav navbar-right">
<li class=nav-item><a data-scroll href=https://uvpicl.live/#top>Home</a></li>
<li class=nav-item><a data-scroll href=https://uvpicl.live/research>Research</a></li>
<li class=nav-item><a data-scroll href=https://uvpicl.live/publication>Publications</a></li>
<li class=nav-item><a data-scroll href=https://uvpicl.live/member>Members</a></li>
<li class=nav-item><a data-scroll href=https://uvpicl.live/post>Blog</a></li>
<li class=nav-item><a data-scroll href=https://uvpicl.live/#contact>Contact</a></li>
</ul>
</div>
</div>
</nav>
<div class=container>
<div class=pub itemscope itemtype=http://schema.org/CreativeWork>
<div class=row>
<div class=col-sm-12>
<div class=pub-title>
<h1 itemprop=name>Identity-aware Facial Expression Recognition via Deep Metric Learning based on Synthesized Images</h1>
</div>
</div>
</div>
<div class=row>
<div class=col-sm-12>
<div class=pub-authors itemprop=author>
<div itemprop=author>
<span class=author-name>
<a href=https://uvpicl.live/member/huangwei/>Wei Huang</a>
</span>,
<span class=author-name>
Siyuan Zhang
</span>,
<span class=author-name>
Peng Zhang*
</span>,
<span class=author-name>
Yufei Zha
</span>,
<span class=author-name>
Yuming Fang
</span>,
<span class=author-name>
Yanning Zhang
</span>
</div>
</div>
</div>
</div>
<div class=row>
<div class=col-sm-12>
<h3>Abstract</h3>
</div>
</div>
<div class=row>
<div class=col-sm-12>
<p class=pub-abstract itemprop=text>Person-dependent facial expression recognition has received considerable research attention in recent years. Unfortunately, different identities can adversely influence recognition accuracy, and the recognition task becomes challenging. Other adverse factors, including limited training data and improper measures of facial expressions, can further contribute to the above dilemma. To solve these problems, a novel identity-aware method is proposed in this study. Furthermore, this study also represents the first attempt to fulfill the challenging person-dependent facial expression recognition task based on deep metric learning and facial image synthesis techniques. Technically, a StarGAN is incorporated to synthesize facial images depicting different but complete basic emotions for each identity to augment the training data. Then, a deep-convolutional-neural-network-based network is employed to automatically extract latent features from both real facial images and all synthesized facial images. Next, a Mahalanobis metric network trained based on extracted latent features outputs a learned metric that measures facial expression differences between images, and the recognition task can thus be realized. Extensive experiments based on several well-known publicly available datasets are carried out in this study for performance evaluations. Person-dependent datasets, including CK+, Oulu (all 6 subdatasets), MMI, ISAFE, ISED, etc., are all incorporated. After comparing the new method with several popular or state-of-the-art facial expression recognition methods, its superiority in person-dependent facial expression recognition can be proposed from a statistical point of view.</p>
</div>
</div>
<div class=row>
<div class=col-sm-12>
<div class=row>
<div class="col-xs-12 col-sm-3 pub-row-heading">Publication</div>
<div class="col-xs-12 col-sm-9">IEEE Transactions on Multimedia</div>
</div>
</div>
</div>
<div class="visible-xs space-below"></div>
<div class=row>
<div class=col-sm-12>
<div class=row>
<div class="col-xs-12 col-sm-3 pub-row-heading">Date</div>
<div class="col-xs-12 col-sm-9" itemprop=datePublished>
July, 2021
</div>
</div>
</div>
</div>
<div class="visible-xs space-below"></div>
<div class=row style=padding-top:10px>
<div class=col-sm-12>
<div class=row>
<div class="col-xs-12 col-sm-3 pub-row-heading" style=line-height:34px>Links</div>
<div class="col-xs-12 col-sm-9">
<a class="btn btn-primary btn-outline" href=https://ieeexplore.ieee.org/document/9479695>PDF</a>
</div>
</div>
</div>
</div>
<div class="visible-xs space-below"></div>
<div class=space-below></div>
<div class=article-style><p>You can add information in $\LaTeX$ and <em>Markdown</em> here.</p>
</div>
</div>
</div>
<footer class=site-footer>
<div class=container>
<p class=powered-by>
Â© UVPICL, 2022 &#183;
<span class=pull-right><a href=#home id=back_to_top><span class=button_icon><i class="fa fa-chevron-up fa-2x" aria-hidden=true></i></span></a></span>
</p>
</div>
</footer>
<script src=//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js></script>
<script type=text/x-mathjax-config>
 MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
</script>
<script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
<script type=text/javascript src=https://cdn.jsdelivr.net/npm/live2d-widget@3.1.4/lib/L2Dwidget.min.js></script>
<script type=text/javascript src=https://cdn.jsdelivr.net/npm/live2d-widget@3.1.4/lib/L2Dwidget.0.min.js></script>
<script type=text/javascript>L2Dwidget.init({model:{scale:1,hHeadPos:.5,vHeadPos:.618,jsonPath:'https://cdn.jsdelivr.net/npm/live2d-widget-model-hijiki@1.0.5/assets/hijiki.model.json'},display:{superSample:2,width:200,height:300,position:'left',hOffset:20,vOffset:0},mobile:{show:!0,scale:1,motion:!0},react:{opacityDefault:1,opacityOnHover:1}});class Circle{constructor({origin:a,speed:b,color:c,angle:d,context:e}){this.origin=a,this.position={...this.origin},this.color=c,this.speed=b,this.angle=d,this.context=e,this.renderCount=0}draw(){this.context.fillStyle=this.color,this.context.beginPath(),this.context.arc(this.position.x,this.position.y,2,0,Math.PI*2),this.context.fill()}move(){this.position.x=Math.sin(this.angle)*this.speed+this.position.x,this.position.y=Math.cos(this.angle)*this.speed+this.position.y+this.renderCount*.3,this.renderCount++}}class Boom{constructor({origin:a,context:b,circleCount:c=16,area:d}){this.origin=a,this.context=b,this.circleCount=c,this.area=d,this.stop=!1,this.circles=[]}randomArray(a){const b=a.length,c=Math.floor(b*Math.random());return a[c]}randomColor(){const a=['8','9','A','B','C','D','E','F'];return'#'+this.randomArray(a)+this.randomArray(a)+this.randomArray(a)+this.randomArray(a)+this.randomArray(a)+this.randomArray(a)}randomRange(a,b){return(b-a)*Math.random()+a}init(){for(let a=0;a<this.circleCount;a++){const b=new Circle({context:this.context,origin:this.origin,color:this.randomColor(),angle:this.randomRange(Math.PI-1,Math.PI+1),speed:this.randomRange(1,6)});this.circles.push(b)}}move(){this.circles.forEach((a,b)=>{if(a.position.x>this.area.width||a.position.y>this.area.height)return this.circles.splice(b,1);a.move()}),this.circles.length==0&&(this.stop=!0)}draw(){this.circles.forEach(a=>a.draw())}}class CursorSpecialEffects{constructor(){this.computerCanvas=document.createElement('canvas'),this.renderCanvas=document.createElement('canvas'),this.computerContext=this.computerCanvas.getContext('2d'),this.renderContext=this.renderCanvas.getContext('2d'),this.globalWidth=window.innerWidth,this.globalHeight=window.innerHeight,this.booms=[],this.running=!1}handleMouseDown(a){const b=new Boom({origin:{x:a.clientX,y:a.clientY},context:this.computerContext,area:{width:this.globalWidth,height:this.globalHeight}});b.init(),this.booms.push(b),this.running||this.run()}handlePageHide(){this.booms=[],this.running=!1}init(){const a=this.renderCanvas.style;a.position='fixed',a.top=a.left=0,a.zIndex='999999999999999999999999999999999999999999',a.pointerEvents='none',a.width=this.renderCanvas.width=this.computerCanvas.width=this.globalWidth,a.height=this.renderCanvas.height=this.computerCanvas.height=this.globalHeight,document.body.append(this.renderCanvas),window.addEventListener('mousedown',this.handleMouseDown.bind(this)),window.addEventListener('pagehide',this.handlePageHide.bind(this))}run(){if(this.running=!0,this.booms.length==0)return this.running=!1;requestAnimationFrame(this.run.bind(this)),this.computerContext.clearRect(0,0,this.globalWidth,this.globalHeight),this.renderContext.clearRect(0,0,this.globalWidth,this.globalHeight),this.booms.forEach((a,b)=>{if(a.stop)return this.booms.splice(b,1);a.move(),a.draw()}),this.renderContext.drawImage(this.computerCanvas,0,0,this.globalWidth,this.globalHeight)}}const cursorSpecialEffects=new CursorSpecialEffects;if(cursorSpecialEffects.init(),window.console){var cons=console;cons&&(cons.group("Hello There !!!"),cons.log("%cWelcome to join our lab","background-image: linear-gradient(#f39800, #f08300, #eb6238);font-size: 4rem;"),cons.groupEnd())}</script>
<script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script>
<div>
<i class="fa fa-user"></i> <span id=busuanzi_value_site_uv></span> visitors
</div>
</body>
</html>